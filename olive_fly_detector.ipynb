{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f092807-58b6-464d-a0dd-ada07121bed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906a02f3-1371-4b2c-9768-29dca69ac5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# scikit-learn imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.feature import hog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea9a9d6-b936-40a7-ba63-ac43e9840383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom transformer for image feature extraction using scikit-learn pipeline\"\"\"\n",
    "    def __init__(self, target_size=(64, 64)):\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features_list = []\n",
    "        \n",
    "        for img in tqdm(X, desc=\"Extracting features\"):\n",
    "            # Ensure correct size\n",
    "            if img.shape[:2] != self.target_size:\n",
    "                img = cv2.resize(img, self.target_size)\n",
    "            \n",
    "            # Convert to grayscale if needed\n",
    "            if len(img.shape) > 2:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Extract features using scikit-learn's image features\n",
    "            hog_feat = hog(img, orientations=8, pixels_per_cell=(16, 16),\n",
    "                               cells_per_block=(1, 1), visualize=False)\n",
    "            \n",
    "            # Basic statistical features\n",
    "            stat_features = [\n",
    "                np.mean(img),\n",
    "                np.std(img),\n",
    "                np.percentile(img, 25),\n",
    "                np.percentile(img, 75)\n",
    "            ]\n",
    "            \n",
    "            # Combine all features\n",
    "            combined_features = np.concatenate([hog_feat, stat_features])\n",
    "            features_list.append(combined_features)\n",
    "            \n",
    "        return np.array(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8468de20-4b42-4045-bf76-e37ec29847b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OliveFlyDetector:\n",
    "    def __init__(self, n_trees=100, max_depth=10):\n",
    "        \"\"\"Initialize detector with scikit-learn pipeline\"\"\"\n",
    "        self.pipeline = Pipeline([\n",
    "            ('feature_extractor', ImageFeatureExtractor()),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', RandomForestClassifier(\n",
    "                n_estimators=n_trees,\n",
    "                max_depth=max_depth,\n",
    "                n_jobs=1,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train the model using scikit-learn pipeline\"\"\"\n",
    "        # Split data for validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        print(\"Training model...\")\n",
    "        start_time = time.time()\n",
    "        # Fixed: Changed fit_transform to fit\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Print validation results\n",
    "        y_pred = self.pipeline.predict(X_val)\n",
    "        print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "        print(\"\\nModel Performance:\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "        \n",
    "    def predict_batch(self, images, image_paths):\n",
    "        \"\"\"Predict multiple images with progress bar\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for img, path in tqdm(zip(images, image_paths), total=len(images), desc=\"Processing images\"):\n",
    "            prediction, probability = self.predict(img)\n",
    "            results.append({\n",
    "                'path': path,\n",
    "                'prediction': 'Olive Fly' if prediction else 'Other Insect',\n",
    "                'confidence': probability[1] if prediction else probability[0]\n",
    "            })\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def predict(self, image):\n",
    "        \"\"\"Predict single image\"\"\"\n",
    "        X = np.array([image])\n",
    "        prediction = self.pipeline.predict(X)[0]\n",
    "        probability = self.pipeline.predict_proba(X)[0]\n",
    "        return prediction, probability\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save scikit-learn pipeline\"\"\"\n",
    "        joblib.dump(self.pipeline, filepath)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath):\n",
    "        \"\"\"Load scikit-learn pipeline\"\"\"\n",
    "        instance = cls()\n",
    "        instance.pipeline = joblib.load(filepath)\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9180eebb-1d15-4a24-94e6-02b8f51dd0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|███████████████████████████████████████████████████████████| 2336/2336 [00:00<00:00, 2535.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|████████████████████████████████████████████████████████| 1868/1868 [00:02<00:00, 779.54it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████| 468/468 [00:00<00:00, 701.31it/s]\n",
      "C:\\Users\\irina\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\irina\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\irina\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in 4.42 seconds\n",
      "\n",
      "Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       400\n",
      "           1       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.85       468\n",
      "   macro avg       0.43      0.50      0.46       468\n",
      "weighted avg       0.73      0.85      0.79       468\n",
      "\n",
      "Model saved to olive_fly_model.joblib\n",
      "\n",
      "Loading test images from test_images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test images: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 45.17it/s]\n",
      "Processing images:   0%|                                                                        | 0/14 [00:00<?, ?it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 332.04it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 335.30it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 199.99it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.98it/s]\n",
      "Processing images:  14%|█████████▏                                                      | 2/14 [00:00<00:01, 10.09it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 478.26it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 281.99it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.17it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 142.92it/s]\n",
      "Processing images:  29%|██████████████████▎                                             | 4/14 [00:00<00:01,  7.98it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.62it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 331.75it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.78it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 199.94it/s]\n",
      "Processing images:  43%|███████████████████████████▍                                    | 6/14 [00:00<00:00,  8.43it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 526.66it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 36.81it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.92it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.15it/s]\n",
      "Processing images:  57%|████████████████████████████████████▌                           | 8/14 [00:00<00:00, 10.42it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.20it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.56it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.44it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 180.92it/s]\n",
      "Processing images:  71%|█████████████████████████████████████████████                  | 10/14 [00:01<00:00, 10.56it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.94it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.68it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 488.11it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 332.59it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.80it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.07it/s]\n",
      "Processing images:  93%|██████████████████████████████████████████████████████████▌    | 13/14 [00:01<00:00, 12.19it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 124.79it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 283.96it/s]\n",
      "Processing images: 100%|███████████████████████████████████████████████████████████████| 14/14 [00:01<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "--------------------------------------------------------------------------------\n",
      "Image                                              | Prediction      | Confidence\n",
      "--------------------------------------------------------------------------------\n",
      "castellar_2_1 156 referencia.JPG                   | Other Insect    | 0.72\n",
      "castellar_2_1 157 referencia.JPG                   | Other Insect    | 0.70\n",
      "castellar_2_1 160 referencia.JPG                   | Other Insect    | 0.61\n",
      "castellar_2_1 162 referencia.JPG                   | Other Insect    | 0.76\n",
      "castellar_2_1 169 referencia.JPG                   | Other Insect    | 0.85\n",
      "castellar_2_1 184 referencia.JPG                   | Other Insect    | 0.71\n",
      "castellar_2_1 191 referencia.JPG                   | Other Insect    | 0.66\n",
      "castellar_2_1 192 referencia.JPG                   | Other Insect    | 0.63\n",
      "castellar_2_1 194 referencia.JPG                   | Other Insect    | 0.71\n",
      "castellar_2_1 196 referencia.JPG                   | Other Insect    | 0.75\n",
      "castellar_2_1 197 referencia.JPG                   | Other Insect    | 0.64\n",
      "castellar_2_1 198 referencia.JPG                   | Other Insect    | 0.75\n",
      "castellar_2_1 205 referencia.JPG                   | Other Insect    | 0.69\n",
      "castellar_2_1 209 referencia.JPG                   | Other Insect    | 0.70\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(data_folder):\n",
    "    \"\"\"Load training data with progress bar\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    paths = []\n",
    "    \n",
    "    data_path = Path(data_folder)\n",
    "    \n",
    "    # Count total files for progress bar\n",
    "    total_files = len(list((data_path / 'olive_flies').glob('*.jpg'))) + \\\n",
    "                  len(list((data_path / 'other_insects').glob('*.jpg')))\n",
    "    \n",
    "    with tqdm(total=total_files, desc=\"Loading dataset\") as pbar:\n",
    "        # Load positive examples\n",
    "        for img_path in (data_path / 'olive_flies').glob('*.jpg'):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(1)\n",
    "                paths.append(str(img_path))\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # Load negative examples\n",
    "        for img_path in (data_path / 'other_insects').glob('*.jpg'):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(0)\n",
    "                paths.append(str(img_path))\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "def predict_images(test_folder, model_path):\n",
    "    \"\"\"Predict all images in a folder\"\"\"\n",
    "    detector = OliveFlyDetector.load_model(model_path)\n",
    "    \n",
    "    # Load test images\n",
    "    images = []\n",
    "    image_paths = []\n",
    "    test_path = Path(test_folder)\n",
    "    \n",
    "    print(f\"\\nLoading test images from {test_folder}...\")\n",
    "    for img_path in tqdm(list(test_path.glob('*.jpg')), desc=\"Loading test images\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            image_paths.append(str(img_path))\n",
    "    \n",
    "    if not images:\n",
    "        print(\"No images found in test folder!\")\n",
    "        return\n",
    "    \n",
    "    # Process all images\n",
    "    results = detector.predict_batch(images, image_paths)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Image':<50} | {'Prediction':<15} | {'Confidence':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    for result in results:\n",
    "        img_name = Path(result['path']).name\n",
    "        print(f\"{img_name:<50} | {result['prediction']:<15} | {result['confidence']:.2f}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution\"\"\"\n",
    "    MODEL_PATH = 'olive_fly_model.joblib'\n",
    "    DATA_FOLDER = 'training_data'\n",
    "    TEST_FOLDER = 'test_images'  # Folder with images to classify\n",
    "    \n",
    "    if not Path(MODEL_PATH).exists():\n",
    "        print(\"Training new model...\")\n",
    "        \n",
    "        # Load dataset\n",
    "        images, labels, _ = load_dataset(DATA_FOLDER)\n",
    "        if len(images) == 0:\n",
    "            print(f\"No training images found in {DATA_FOLDER}\")\n",
    "            print(\"Please create folders:\")\n",
    "            print(f\"  {DATA_FOLDER}/olive_flies/\")\n",
    "            print(f\"  {DATA_FOLDER}/other_insects/\")\n",
    "            return\n",
    "        \n",
    "        # Train detector\n",
    "        detector = OliveFlyDetector()\n",
    "        detector.train(images, labels)\n",
    "        detector.save_model(MODEL_PATH)\n",
    "        print(f\"Model saved to {MODEL_PATH}\")\n",
    "    \n",
    "    # Predict test images\n",
    "    predict_images(TEST_FOLDER, MODEL_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3babce-7396-459e-933a-5b90ff834c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26f7f5-667d-4057-8395-9e2331dd7009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
