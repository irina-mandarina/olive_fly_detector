{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906a02f3-1371-4b2c-9768-29dca69ac5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For image processing\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "\n",
    "# For progress bar\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea9a9d6-b936-40a7-ba63-ac43e9840383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Feature extractor\"\"\"\n",
    "    def __init__(self, target_size=(64, 64)):\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def extract_shape_features(self, img):\n",
    "        \"\"\"Extract shape-based features\"\"\"\n",
    "        # Find contours\n",
    "        thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            # Shape features\n",
    "            area = cv2.contourArea(largest_contour)\n",
    "            perimeter = cv2.arcLength(largest_contour, True)\n",
    "            circularity = 4 * np.pi * area / (perimeter * perimeter) if perimeter > 0 else 0\n",
    "            \n",
    "            # Bounding box features\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            aspect_ratio = float(w)/h if h > 0 else 0\n",
    "            extent = float(area)/(w*h) if w*h > 0 else 0\n",
    "            \n",
    "            return [area, perimeter, circularity, aspect_ratio, extent]\n",
    "        return [0, 0, 0, 0, 0]\n",
    "    \n",
    "    def extract_texture_features(self, img):\n",
    "        \"\"\"Extract texture-based features\"\"\"\n",
    "        # Gray-Level Co-occurrence Matrix\n",
    "        glcm = self.calculate_glcm(img)\n",
    "        contrast = np.sum(((np.arange(256)[:, None] - np.arange(256)) ** 2) * glcm)\n",
    "        correlation = np.sum(glcm * np.outer(np.arange(256), np.arange(256)))\n",
    "        energy = np.sum(glcm ** 2)\n",
    "        homogeneity = np.sum(glcm / (1 + (np.arange(256)[:, None] - np.arange(256)) ** 2))\n",
    "        \n",
    "        return [contrast, correlation, energy, homogeneity]\n",
    "    \n",
    "    def calculate_glcm(self, img):\n",
    "        \"\"\"Calculate Gray-Level Co-occurrence Matrix\"\"\"\n",
    "        glcm = np.zeros((256, 256))\n",
    "        for i in range(img.shape[0]-1):\n",
    "            for j in range(img.shape[1]-1):\n",
    "                i_val = img[i,j]\n",
    "                j_val = img[i,j+1]\n",
    "                glcm[i_val,j_val] += 1\n",
    "        glcm = glcm / np.sum(glcm)\n",
    "        return glcm\n",
    "    \n",
    "    def extract_intensity_features(self, img):\n",
    "        \"\"\"Extract intensity-based features\"\"\"\n",
    "        hist = cv2.calcHist([img], [0], None, [32], [0, 256]).flatten()\n",
    "        hist = hist / np.sum(hist)  # Normalize\n",
    "        \n",
    "        return [\n",
    "            np.mean(img),           # Mean intensity\n",
    "            np.std(img),            # Standard deviation\n",
    "            np.percentile(img, 25), # First quartile\n",
    "            np.percentile(img, 75), # Third quartile\n",
    "            np.max(img),            # Maximum intensity\n",
    "            np.min(img),            # Minimum intensity\n",
    "            np.median(img),         # Median intensity\n",
    "            *hist                   # Histogram\n",
    "        ]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features_list = []\n",
    "        \n",
    "        for img in tqdm(X, desc=\"Extracting features\"):\n",
    "            # Resize and convert to grayscale\n",
    "            if img.shape[:2] != self.target_size:\n",
    "                img = cv2.resize(img, self.target_size)\n",
    "            if len(img.shape) > 2:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # HOG features\n",
    "            hog_feat = hog(img, orientations=8, pixels_per_cell=(16, 16),\n",
    "                               cells_per_block=(1, 1), visualize=False)\n",
    "            \n",
    "            # Shape features\n",
    "            shape_features = self.extract_shape_features(img)\n",
    "            \n",
    "            # Texture features\n",
    "            texture_features = self.extract_texture_features(img)\n",
    "            \n",
    "            # Intensity features\n",
    "            intensity_features = self.extract_intensity_features(img)\n",
    "            \n",
    "            # Combine all features\n",
    "            combined_features = np.concatenate([\n",
    "                hog_feat,\n",
    "                shape_features,\n",
    "                texture_features,\n",
    "                intensity_features\n",
    "            ])\n",
    "            \n",
    "            features_list.append(combined_features)\n",
    "        \n",
    "        return np.array(features_list)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8468de20-4b42-4045-bf76-e37ec29847b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OliveFlyDetector:\n",
    "    def __init__(self, n_trees=100, max_depth=10):\n",
    "        \"\"\"Initialize detector with scikit-learn pipeline\"\"\"\n",
    "        self.pipeline = Pipeline([\n",
    "            ('feature_extractor', ImageFeatureExtractor()),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', RandomForestClassifier(\n",
    "                n_estimators=n_trees,\n",
    "                max_depth=max_depth,\n",
    "                n_jobs=1,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train the model using scikit-learn pipeline\"\"\"\n",
    "        # Split data for validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        print(\"Training model...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Display validation results\n",
    "        y_pred = self.pipeline.predict(X_val)\n",
    "        print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "        print(\"\\nModel Performance:\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "        \n",
    "    def predict_batch(self, images, image_paths):\n",
    "        \"\"\"Predict multiple images with progress bar\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for img, path in tqdm(zip(images, image_paths), total=len(images), desc=\"Processing images\"):\n",
    "            prediction, probability = self.predict(img)\n",
    "            results.append({\n",
    "                'path': path,\n",
    "                'prediction': 'Olive Fly' if prediction else 'Not Olive Fly',\n",
    "                'confidence': probability[1] if prediction else probability[0]\n",
    "            })\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def predict(self, image):\n",
    "        \"\"\"Predict single image\"\"\"\n",
    "        X = np.array([image])\n",
    "        prediction = self.pipeline.predict(X)[0]\n",
    "        probability = self.pipeline.predict_proba(X)[0]\n",
    "        return prediction, probability\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save scikit-learn pipeline\"\"\"\n",
    "        joblib.dump(self.pipeline, filepath)\n",
    "    \n",
    "    # With this annotation the method will be bound to the class itself and not the instance of the class\n",
    "    @classmethod\n",
    "    def load_model(cls, filepath):\n",
    "        \"\"\"Load scikit-learn pipeline\"\"\"\n",
    "        instance = cls()\n",
    "        instance.pipeline = joblib.load(filepath)\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9180eebb-1d15-4a24-94e6-02b8f51dd0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████| 601/601 [00:08<00:00, 69.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████████████████████████████████████████████████████| 480/480 [00:04<00:00, 112.47it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████| 121/121 [00:01<00:00, 97.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in 5.12 seconds\n",
      "\n",
      "Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79        58\n",
      "           1       0.84      0.73      0.78        63\n",
      "\n",
      "    accuracy                           0.79       121\n",
      "   macro avg       0.79      0.79      0.78       121\n",
      "weighted avg       0.79      0.79      0.78       121\n",
      "\n",
      "Model saved to olive_fly_model.joblib\n",
      "\n",
      "Loading test images from test_images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test images: 100%|████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 609.09it/s]\n",
      "Processing images:   0%|                                                                        | 0/26 [00:00<?, ?it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 49.96it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.11it/s]\n",
      "Processing images:   4%|██▍                                                             | 1/26 [00:00<00:04,  6.20it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.48it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 52.34it/s]\n",
      "Processing images:   8%|████▉                                                           | 2/26 [00:00<00:03,  6.88it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 77.21it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 130.48it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 116.21it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 105.53it/s]\n",
      "Processing images:  15%|█████████▊                                                      | 4/26 [00:00<00:02,  9.87it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 111.17it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 22.68it/s]\n",
      "Processing images:  19%|████████████▎                                                   | 5/26 [00:00<00:02,  9.85it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 37.67it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 34.47it/s]\n",
      "Processing images:  23%|██████████████▊                                                 | 6/26 [00:00<00:02,  8.20it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 49.51it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 142.11it/s]\n",
      "Processing images:  27%|█████████████████▏                                              | 7/26 [00:00<00:02,  8.08it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 78.38it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.71it/s]\n",
      "Processing images:  31%|███████████████████▋                                            | 8/26 [00:01<00:03,  5.83it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 73.63it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 83.22it/s]\n",
      "Processing images:  35%|██████████████████████▏                                         | 9/26 [00:01<00:02,  6.12it/s]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 105.06it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 70.21it/s]\n",
      "Processing images:  38%|████████████████████████▏                                      | 10/26 [00:01<00:02,  6.29it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 96.23it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 131.27it/s]\n",
      "\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 125.04it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 30.30it/s]\n",
      "Processing images:  46%|█████████████████████████████                                  | 12/26 [00:01<00:02,  6.75it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 37.04it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 43.46it/s]\n",
      "Processing images:  50%|███████████████████████████████▌                               | 13/26 [00:01<00:01,  6.57it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.66it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.44it/s]\n",
      "Processing images:  54%|█████████████████████████████████▉                             | 14/26 [00:02<00:01,  6.60it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.48it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 48.75it/s]\n",
      "Processing images:  58%|████████████████████████████████████▎                          | 15/26 [00:02<00:01,  6.61it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 42.49it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 35.72it/s]\n",
      "Processing images:  62%|██████████████████████████████████████▊                        | 16/26 [00:02<00:01,  6.64it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 36.78it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.67it/s]\n",
      "Processing images:  65%|█████████████████████████████████████████▏                     | 17/26 [00:02<00:01,  6.97it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.83it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 51.66it/s]\n",
      "Processing images:  69%|███████████████████████████████████████████▌                   | 18/26 [00:02<00:01,  7.33it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.11it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.76it/s]\n",
      "Processing images:  73%|██████████████████████████████████████████████                 | 19/26 [00:02<00:00,  7.27it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 81.82it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.47it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 43.45it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.89it/s]\n",
      "Processing images:  81%|██████████████████████████████████████████████████▉            | 21/26 [00:02<00:00,  7.81it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 50.01it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.77it/s]\n",
      "Processing images:  85%|█████████████████████████████████████████████████████▎         | 22/26 [00:03<00:00,  7.90it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 49.91it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 52.58it/s]\n",
      "Processing images:  88%|███████████████████████████████████████████████████████▋       | 23/26 [00:03<00:00,  7.63it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 74.05it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 60.86it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.09it/s]\n",
      "Processing images:  96%|████████████████████████████████████████████████████████████▌  | 25/26 [00:03<00:00,  8.11it/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.49it/s]\n",
      "\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 52.02it/s]\n",
      "Processing images: 100%|███████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "--------------------------------------------------------------------------------\n",
      "Image                                              | Prediction      | Confidence\n",
      "--------------------------------------------------------------------------------\n",
      "castellar_2_1 111 referencia.JPG                   | Not Olive Fly   | 0.91\n",
      "castellar_2_1 212 referencia.JPG                   | Olive Fly       | 0.78\n",
      "castellar_2_1 213 referencia.JPG                   | Olive Fly       | 0.82\n",
      "castellar_2_1 214 referencia.JPG                   | Not Olive Fly   | 0.53\n",
      "castellar_2_1 225 referencia.JPG                   | Not Olive Fly   | 0.87\n",
      "castellar_2_1 226 referencia.JPG                   | Not Olive Fly   | 0.76\n",
      "castellar_2_1 227 referencia.JPG                   | Olive Fly       | 0.77\n",
      "castellar_2_1 228 referencia.JPG                   | Not Olive Fly   | 0.76\n",
      "castellar_2_1 229 referencia.JPG                   | Olive Fly       | 0.79\n",
      "castellar_2_1 230 referencia.JPG                   | Olive Fly       | 0.91\n",
      "castellar_2_1 231 referencia.JPG                   | Olive Fly       | 0.69\n",
      "castellar_2_1 232 referencia.JPG                   | Olive Fly       | 0.60\n",
      "castellar_2_1 233 referencia.JPG                   | Olive Fly       | 0.80\n",
      "castellar_2_1 247 referencia.JPG                   | Olive Fly       | 0.73\n",
      "castellar_2_1 248 referencia.JPG                   | Olive Fly       | 0.89\n",
      "castellar_2_1 251 referencia.JPG                   | Olive Fly       | 0.80\n",
      "castellar_2_1 252 referencia.JPG                   | Olive Fly       | 0.85\n",
      "moral_1 184 referencia.JPG                         | Olive Fly       | 0.96\n",
      "moral_1 205 referencia.JPG                         | Olive Fly       | 0.93\n",
      "moral_1 214 referencia.JPG                         | Olive Fly       | 0.73\n",
      "moral_1 245 referencia.JPG                         | Olive Fly       | 0.97\n",
      "moral_1 31 referencia.JPG                          | Olive Fly       | 0.85\n",
      "moral_1 40 referencia.JPG                          | Olive Fly       | 0.93\n",
      "moral_1 43 referencia.JPG                          | Olive Fly       | 0.94\n",
      "moral_1 44 referencia.JPG                          | Olive Fly       | 0.90\n",
      "moral_1 51 referencia.JPG                          | Olive Fly       | 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(data_folder):\n",
    "    \"\"\"Load training data with progress bar\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    paths = []\n",
    "    \n",
    "    data_path = Path(data_folder)\n",
    "    \n",
    "    # Count total files for progress bar\n",
    "    total_files = len(list((data_path / 'olive_fly').glob('*.jpg'))) + \\\n",
    "                  len(list((data_path / 'not_olive_fly').glob('*.jpg')))\n",
    "    \n",
    "    with tqdm(total=total_files, desc=\"Loading dataset\") as pbar:\n",
    "        # Load positive examples\n",
    "        for img_path in (data_path / 'olive_fly').glob('*.jpg'):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(1)\n",
    "                paths.append(str(img_path))\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # Load negative examples\n",
    "        for img_path in (data_path / 'not_olive_fly').glob('*.jpg'):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(0)\n",
    "                paths.append(str(img_path))\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "def predict_images(test_folder, model_path):\n",
    "    \"\"\"Predict all images in a folder\"\"\"\n",
    "    detector = OliveFlyDetector.load_model(model_path)\n",
    "    \n",
    "    # Load test images\n",
    "    images = []\n",
    "    image_paths = []\n",
    "    test_path = Path(test_folder)\n",
    "    \n",
    "    print(f\"\\nLoading test images from {test_folder}...\")\n",
    "    for img_path in tqdm(list(test_path.glob('*.jpg')), desc=\"Loading test images\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            image_paths.append(str(img_path))\n",
    "    \n",
    "    if not images:\n",
    "        print(\"No images found in test folder!\")\n",
    "        return\n",
    "    \n",
    "    # Process all images\n",
    "    results = detector.predict_batch(images, image_paths)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Image':<50} | {'Prediction':<15} | {'Confidence':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    for result in results:\n",
    "        img_name = Path(result['path']).name\n",
    "        print(f\"{img_name:<50} | {result['prediction']:<15} | {result['confidence']:.2f}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution\"\"\"\n",
    "    MODEL_PATH = 'olive_fly_model.joblib'\n",
    "    DATA_FOLDER = 'training_data' # Folder with training data\n",
    "    TEST_FOLDER = 'test_images'  # Folder with images to classify\n",
    "    \n",
    "    if not Path(MODEL_PATH).exists():\n",
    "        print(\"Training new model...\")\n",
    "        \n",
    "        # Load dataset\n",
    "        images, labels, _ = load_dataset(DATA_FOLDER)\n",
    "        if len(images) == 0:\n",
    "            print(f\"No training images found in {DATA_FOLDER}\")\n",
    "            print(\"Please create folders:\")\n",
    "            print(f\"  {DATA_FOLDER}/olive_fly/\")\n",
    "            print(f\"  {DATA_FOLDER}/not_olive_fly/\")\n",
    "            return\n",
    "        \n",
    "        # Train detector\n",
    "        detector = OliveFlyDetector()\n",
    "        detector.train(images, labels)\n",
    "        detector.save_model(MODEL_PATH)\n",
    "        print(f\"Model saved to {MODEL_PATH}\")\n",
    "    \n",
    "    # Predict test images\n",
    "    predict_images(TEST_FOLDER, MODEL_PATH)\n",
    "\n",
    "def detect_olive_fly(image):\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3babce-7396-459e-933a-5b90ff834c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26f7f5-667d-4057-8395-9e2331dd7009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
